# This configuration gives a head start to integrate the chainkit values in your own ELK stack. Refer the steps as "chainkit step" to go over them and add in your existing setup.
# Or you can use this file as headstart by simply copying the file to /etc/logstash/conf.d/chainkit_initial_draft.conf and restart the logstash
#
# Pre requisite: You need to have ck filter installed in your logstash setup
# To do so, download the file at: https://github.com/chainkit/logstash-filter-ck/blob/master/prebuilt/logstash-filter-ck-1.0.0.gem
# Go to: /usr/share/logstash folder by running cd /usr/share/logstash
#
# Install the plugin as ./bin/logstash-plugin install logstash-filter-ck-1.0.0.gem
#
# After that add below env variable in /etc/default/logstash (can be added at end). Refer sample env variable as below to run the chainkit:
#
# ES_ENDPOINT_1="localhost:9200"
# ES_USER="es_user"
# ES_PASSWORD="secret"
# CK_USER="chainkit_user"
# CK_PASSWORD="secret"
# CK_STORAGE="none"
# CK_TCP_PORT="23456"
# CK_VERIFY_SCHEDULE="*/5 * * * *"
# ES_INDEX="ck-input-tcp"
#
# Once everything is configured, restart the logstash as: systemctl restart logstash

input {
	tcp {
		port => "${CK_TCP_PORT:23456}"

		# chainkit step 1 for register: Add this part in your existing input plugin, this is to specify whether this event will be undergoing to register or not
		add_field => {
			isRegister => "true"
		}
		# Chainkit step 1 End:
	}
	# End input TCP 

	# chainkit step 2 for verify: Add this part in your input section, this is to specify whether this event will be undergoing to verify or not
	elasticsearch {
		hosts => ["${ES_ENDPOINT_1:localhost}"]
		# Index which needs to be monitored for verify
		index => "${ES_INDEX:ck-*}"

		# Interval at which verify needs to be run
		schedule => "${CK_VERIFY_SCHEDULE:*/5 * * * *}"

		# Query to fetch specific data for verify which fetch the data for last 30 min as per now-30m, to change it to last 1 hour make a change and add: now-1h, for last 7 day, change it to now-7d
		query => '{"query":{"bool":{"must":[{"range":{"@timestamp":{"gte":"now-30m","lte":"now","time_zone":"UTC"}}}]}}}'

		# Add a field so as in filter we can be sure this needs to go to verify not the register
		add_field => {
			isVerify => "true"
		}
		ssl => true
		docinfo => true
		user => "${ES_USER:es_user}"
		password => "${ES_PASSWORD:secret}"
		ca_file => "/etc/logstash/elasticCA.crt"
	}
	# Chainkit step 2 End:

}

filter {
	# chainkit step 3 to register the event: Add this part in your existing filter section at the end, after performing all your filters and extracting out the final info. 
	if [isRegister] == "true" {
		# isRegister field is added just for the condition and don't need to be stored to elasticsearch, hence removing before passing it to register API
		mutate {
			remove_field => ["isRegister"]
		}

		# Actual CK filter to perform the register, add the credentials here or manage them by default logstash env at : /etc/default/logstash
		ck {
			username => "${CK_USER:chainkit_user}"
			password => "${CK_PASSWORD:secret}"
			storage => "${CK_STORAGE:none}"
		}
		# End ckRegister

		# This is in place to have a basic test of tampering, here we are replacing few words in message with another. For example, if your message has alice it gets replaced with bob. As this is done after registering the event hence the verification should be "false" for these conditions. Feel free to remove in the final version. 
		mutate {
			gsub => [
				"message", "alice", "bob",
				"message", "foo", "bar",
				"message", "tom", "jerry",
				"message", "java", "scala"
			]
		}
	}
	# End filter isRegister
	# Chainkit step 3 End:
		
	# chainkit step 4 to verify the event: Add this part in your existing filter section at the end jut after register. 
	# We added the field as isVerify in the input just to identify if this needs to go with verify or not
	if [isVerify] == "true" {
		# Remove the field as verified (stored after registering hence not part of register) and isVerify (new field added as verify input, so new field and was not registered)
		mutate {
			remove_field => ["verified", "isVerify"]
		}

		# Actual CK filter to perform the verify, add the credentials here or manage them by default logstash env at : /etc/default/logstash
		ckverify {
			username => "${CK_USER:chainkit_user}"
			password => "${CK_PASSWORD:secret}"
			storage => "${CK_STORAGE:none}"
		}

		# Convert the datatype of field verified to string explicitly
		mutate {
			convert => {
				"verified" => "string"
			}
		}

		# Remove all the fields other than verified, as we dont need to send all data again
		prune {
			whitelist_names => [ "verified" ]
		}
	}
	# Chainkit step 4 End:		
}

output {
	# chainkit step 5 to index the data which has been registered, Add this section to your existing output block of elasticsearch.
	# If this was passed via register then it will have the field as entityid, so checking for that and if there index it accordingly as per your own index naming
	if [entityid] {
		elasticsearch {
			hosts => ["${ES_ENDPOINT_1:localhost}"]
			cacert => "/etc/logstash/elasticCA.crt"
			# Change the index name if you want to, same should be changed in the input section of verify too
			index => "${ES_INDEX:ck-input-tcp}"
			user => "${ES_USER:es_user}"
			password => "${ES_PASSWORD:secret}"
			# If you have own logic for uniqueId generation, skip this and use your's, else can use entityid and uuid generated by register which would be unique
			document_id => "%{entityid}-%{uuid}"
			ssl => "true"
		}
	}
	# Chainkit step 5 End:		
	
	# chainkit step 6 to index the data which has been verified, Add this section to your existing output block of elasticsearch.
	# Checking if log events has the field verified with value as true or false (verified would be returned after the event goes through with the ckverify step)
	if ([verified] == "true" or [verified] == "false") {
		elasticsearch {
			hosts => ["${ES_ENDPOINT_1:localhost}"]
			cacert => "/etc/logstash/elasticCA.crt"
			user => "${ES_USER:es_user}"
			password => "${ES_PASSWORD:secret}"
			index => "%{[@metadata][_index]}"
			doc_as_upsert => "true"
			action => "update"
			document_type => "%{[@metadata][_type]}"
			document_id => "%{[@metadata][_id]}"
			ssl => "true"
		}
	}
	# Chainkit step 6 End:	
}
